# raspberry_faces_workflow.py - Raspberry Pi version adapted to Flask interface & Picamera2 with warm-up, preview and diagnostics

from picamera2 import Picamera2
import cv2
import os
import numpy as np
import pandas as pd
import csv
from datetime import datetime
import argparse
import time

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
FACES_DIR = os.path.join(BASE_DIR, 'faces')
LABELS_CSV = os.path.join(BASE_DIR, 'labels.csv')
DETECTIONS_CSV = os.path.join(BASE_DIR, 'detections.csv')
TRAINER_YML = os.path.join(BASE_DIR, 'trainer.yml')

def load_labels():
    labels = {}
    if os.path.exists(LABELS_CSV):
        with open(LABELS_CSV, 'r', newline='', encoding='utf-8') as f:
            reader = csv.reader(f)
            for row in reader:
                if len(row) == 2:
                    labels[int(row[0])] = row[1]
    return labels

def save_label(label, name):
    labels = load_labels()
    if label not in labels:
        with open(LABELS_CSV, 'a', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow([label, name])

def warmup_camera(picam2, warmup_time=1.0, discard_frames=3):
    print("Warming up camera...")
    time.sleep(warmup_time)
    for _ in range(discard_frames):
        _ = picam2.capture_array()
    print("Camera ready.")

def collect_faces(name=None, num_samples=20):
    if name is None:
        name = input("Enter the person's name: ").strip()
    else:
        name = name.strip()

    os.makedirs(FACES_DIR, exist_ok=True)
    labels = load_labels()
    if name in labels.values():
        label = [k for k, v in labels.items() if v == name][0]
    else:
        label = max(labels.keys(), default=0) + 1
        save_label(label, name)

    picam2 = Picamera2()
    config = picam2.create_preview_configuration(main={"size": (640, 480)})
    picam2.configure(config)
    picam2.start()
    warmup_camera(picam2)

    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    count = 0

    while count < num_samples:
        frame = picam2.capture_array()
        cv2.imshow("Face Capture", frame)
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.3, 5)
        for (x, y, w, h) in faces:
            roi = gray[y:y+h, x:x+w]
            roi = cv2.resize(roi, (200, 200))
            filename = os.path.join(FACES_DIR, f"{label}_{count}.jpg")
            cv2.imwrite(filename, roi)
            print(f"Saved: {filename}")
            count += 1
            if count >= num_samples:
                break
        if cv2.waitKey(100) & 0xFF == ord('q'):
            break

    picam2.close()
    cv2.destroyAllWindows()
    print(f"Collected {count} samples for {name}.")

def train_recognizer():
    recognizer = cv2.face.LBPHFaceRecognizer_create()
    faces, labels = [], []
    for filename in os.listdir(FACES_DIR):
        if filename.endswith('.jpg'):
            img_path = os.path.join(FACES_DIR, filename)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is None:
                continue
            label = int(filename.split('_')[0])
            faces.append(img)
            labels.append(label)
    if not faces:
        print("No faces found to train.")
        return False
    recognizer.train(faces, np.array(labels))
    recognizer.save(TRAINER_YML)
    print("Training complete.")
    return True

def recognize(max_runtime=180, idle_timeout=60):
    if not os.path.exists(TRAINER_YML):
        print("Trained model not found.")
        return

    recognizer = cv2.face.LBPHFaceRecognizer_create()
    recognizer.read(TRAINER_YML)
    label_map = load_labels()
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

    picam2 = Picamera2()
    config = picam2.create_preview_configuration(main={"size": (640, 480)})
    picam2.configure(config)
    start_time = time.time()
    picam2.start()
    warmup_camera(picam2)
    print(f"Camera started in {time.time() - start_time:.2f} seconds")

    start_time = time.time()
    last_seen = start_time

    try:
        while True:
            frame = picam2.capture_array()
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = face_cascade.detectMultiScale(gray, 1.3, 5)

            if len(faces) > 0:
                last_seen = time.time()
                for (x, y, w, h) in faces:
                    roi = gray[y:y+h, x:x+w]
                    roi = cv2.resize(roi, (200, 200))
                    try:
                        label, confidence = recognizer.predict(roi)
                        name = label_map.get(label, f"Unknown ({label})")

                        # Draw rectangle and label on frame
                        color = (0, 255, 0) if confidence < 70 else (0, 0, 255)
                        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)
                        cv2.putText(frame, name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

                        with open(DETECTIONS_CSV, 'a', newline='', encoding='utf-8') as f:
                            writer = csv.writer(f)
                            writer.writerow([datetime.now().isoformat(), name, confidence])
                    except:
                        continue

            cv2.imshow("Recognition", frame)

            if time.time() - start_time > max_runtime:
                print("Max runtime reached. Exiting.")
                break
            if time.time() - last_seen > idle_timeout:
                print("No face detected for a while. Exiting.")
                break
            if cv2.waitKey(100) & 0xFF == ord('q'):
                print("User requested quit.")
                break

    finally:
        picam2.close()
        cv2.destroyAllWindows()
        print("Recognition session ended.")

def camera_preview(timeout=5):
    picam2 = Picamera2()
    config = picam2.create_preview_configuration(main={"size": (640, 480)})
    picam2.configure(config)
    picam2.start()
    warmup_camera(picam2)
    print(f"Camera preview active. Waiting {timeout} seconds to start...")

    start = time.time()
    while True:
        frame = picam2.capture_array()
        cv2.imshow("Camera Preview", frame)
        if time.time() - start >= timeout:
            print("Auto-starting after preview timeout.")
            picam2.close()
            cv2.destroyAllWindows()
            return True

        key = cv2.waitKey(100) & 0xFF
        if key in [ord('s'), ord('S')]:
            picam2.close()
            cv2.destroyAllWindows()
            return True
        elif key in [ord('q'), ord('Q')]:
            picam2.close()
            cv2.destroyAllWindows()
            return False

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--mode', choices=['add', 'train', 'recognize'], required=True)
    parser.add_argument('--name', help='Name of person (used in add mode)')
    args = parser.parse_args()

    if args.mode == 'add':
        if camera_preview():
            collect_faces(args.name)
            train_recognizer()
    elif args.mode == 'train':
        train_recognizer()
    elif args.mode == 'recognize':
        recognize()
